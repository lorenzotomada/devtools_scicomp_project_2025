{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation \n",
    "**Disclaimer**: *this document is not meant to be neither a formal nor an exhaustive description of the iterative method to solve the eigenvalue problem. The aim of this text is only to provide the necessary and minimal information needed for the reader to understand the code implementation. We will use these pages to document, explain and justify the choice made from a numerical and scientific computing standpoint*.\n",
    "\n",
    "## Problem statement\n",
    "Given a matrix $\\boldsymbol{A} \\in \\mathbb{C}^{n, n}$, with $n \\in \\mathbb{N}$ the matrix dimension, the eigenvalue problem can be formulated as finding the eigenpair $\\{(\\lambda_i, \\boldsymbol{v}_i)\\}_{i=1} ^ n$, with $\\lambda_i \\in \\mathbb{C}$, $\\boldsymbol{v}_i \\in \\mathbb{C}^{n ,1}$ and $\\boldsymbol{v}_i \\ne \\boldsymbol{0}$ such that \n",
    "$$\\boldsymbol{A} \\boldsymbol{v}_i = \\lambda_i \\boldsymbol{v}_i, \\quad i=1, 2, ..., n $$\n",
    "\n",
    "$\\lambda_i$ are called eigenvalue, while $\\boldsymbol{v}_i$ are the corresponding eigenvectors. Theoretically, finding the matrix's eigenvalue is possible by imposing the following condition:\n",
    "$$ \\det(A-\\lambda I)=0 $$\n",
    "which lead to the well known characteristic polynomial of degree $n$. The eigenvalue are the roots of the characteristic polynomial. Although correct, this apporach is not viable, due to the difficulties in both expressing the characteristic polynomial and find its roots, when the Matrix gets very large.\n",
    "\n",
    "Numerical methods takle the eigenproblem using a different strategy, most of the time being a iterative methods. Rather than aspire to get the exact solution, they seek after an approximation of the solution, which hopefully, under a set of conditions, converges to the exact solution.\n",
    "Among all the method devolped to solve the eigenproblem, the power method, along with its variants suct that the inverse power method and power method with shift, and the QR are the widest spread and the most used.\n",
    "\n",
    "## Power method\n",
    "Let $\\boldsymbol{A}$ being a matric and $\\lambda _i$ the eigenvalue already sorted accordingly to their module. If\n",
    "$$ |\\lambda_1| > |\\lambda _i | \\quad i=2, 3, ..., n$$\n",
    "then the power method allow to recover the eigenpair $(\\lambda_1, \\boldsymbol{v}_1)$ by applying iteratively, the following steps\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\textbf{Power Method Algorithm} \\\\\n",
    "\\textbf{Input:} A \\in \\mathbb{C}^{n \\times n}, \\text{initial vector } x_0, \\text{ tolerance } \\text{tol}, \\text{ max iterations } \\text{max\\_iter} \\\\\n",
    "\\textbf{Output:} \\lambda \\text{ (dominant eigenvalue approximation), } x \\text{ (eigenvector approximation)} \\\\\n",
    "\n",
    "1.\\ \\text{Initialize } x = x_0 \\text{ (random or chosen guess)} \\\\\n",
    "2.\\ \\text{Normalize } x \\text{: } y^{(1)} = x/ \\| x\\| \\\\\n",
    "3.\\ \\lambda_{\\text{old}} = 0 \\\\\n",
    "\n",
    "4.\\ \\textbf{for } k = 1 \\textbf{ to } \\text{max\\_iter} \\textbf{ do} \\\\\n",
    "\\quad 5.\\ x^{(k+1)} = A \\cdot y^{(k)} \\\\\n",
    "\\quad 6.\\  y^{(k+1)} = x^{(k+1)}/ \\| x^{(k+1)}\\|  \\\\\n",
    "\\quad 7.\\  \\lambda^{(k+1)} =  (y^{(k+1)})^H \\boldsymbol{A} y^{(k+1)} \\\\\n",
    "\\quad 8.\\ \\textbf{if } |\\lambda^{(k+1)} - \\lambda^{(k)}| < \\text{tol} \\textbf{ then} \\\\\n",
    "\\quad \\quad \\text{Break (convergence reached)} \\\\\n",
    "\n",
    "9.\\ \\textbf{Return } \\lambda, x\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "By exploiting Matrix properties, it is also possible to find the eigenvalue with the smallest norm, and its associated eigenvector, or either the the eigenvalue closest to a given number.\n",
    "\n",
    "## QR algorithm\n",
    "Being the problem we are interested in to solve incolve a symmetric Matrix, we will start introduce the QR alforithm in a general way and specialize it for the case of symmetric matrices as soon as we have the chance.\n",
    "\n",
    "The QR algorithm can be divide in to two stages: during the first stage, the matrix is reduced, by means of similar trasformation, into a Hessemberg matrix, or, for Hermetian matrix, into a tridiagonal matrix. Although the QR algorithm can be applied directly to a full matrix, it converges faster if it is applied to Hessemberg Matrix or triagular matrices, with also a smaller computational cost.\n",
    "\n",
    "## Profiling\n",
    "\n",
    "In this section we show the profiling and function's optimization based on the profiling analysys. \n",
    "\n",
    "### About the algorithm\n",
    "Given the symmetry of the matrix $\\boldsymbol{A}$, we choose the algorithm specialized for this kind of matrices, that allowed for the lowest computational complexity. For instance, to ease the convergence of the QR algrithm, a similarity reduction of the original matrices to a \"simpler\" matrix is required. If for a general matrices, the reduction using the Householder reflector leads to a quasi upper triangular Hessemberg matrix. The cost of this reduction amounts to $O(\\frac{14}{3} n^3)$.\n",
    "If the original matrix is symmetric, the Hessemberg matrix must be symmetric too, leading to a tridiagonal Matrix. The algorithm implied for this reduction is the Lanczos algorithm, which scales approximatly as $O(2n^2)$. Apart from this algorithm optimization the Lanczos algorithm does not lend itsel to any kind of optimization. Whenever possible, to improve performance, numpy function and operator are used to improve performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit, prange\n",
    "from line_profiler import profile, LineProfiler\n",
    "from time import time\n",
    "\n",
    "def Lanczos_PRO_original(A, q, m=None, toll=np.sqrt(np.finfo(float).eps)):\n",
    "    \"\"\"\n",
    "    Perform the Lanczos algorithm for symmetric matrices.\n",
    "    This function computes an orthogonal matrix Q and tridiagonal matrix T such that A ≈ Q * T * Q.T,\n",
    "    where A is a symmetric matrix. The algorithm is useful for finding a few eigenvalues and eigenvectors\n",
    "    of large symmetric matrices.\n",
    "    Args:\n",
    "        A (np.ndarray): A symmetric square matrix of size n x n.\n",
    "        q (np.ndarray): Initial vector of size n.\n",
    "        m (int, optional): Number of eigenvalues to compute. Must be less than or equal to n.\n",
    "                           If None, defaults to the size of A.\n",
    "\n",
    "\n",
    "        tuple: A tuple (Q, alpha, beta) where:\n",
    "\n",
    "\n",
    "            - Q (np.ndarray): Orthogonal matrix of size n x m.\n",
    "\n",
    "\n",
    "            - alpha (np.ndarray): Vector of size m containing the diagonal elements of the tridiagonal matrix.\n",
    "\n",
    "\n",
    "            - beta (np.ndarray): Vector of size m-1 containing the off-diagonal elements of the tridiagonal matrix.\n",
    "    Raises:\n",
    "        ValueError: If the input matrix A is not square or if m is greater than the size of A.\n",
    "    \"\"\"\n",
    "    if m == None:\n",
    "        m = A.shape[0]\n",
    "\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        raise ValueError(\"Input matrix A must be square.\")\n",
    "\n",
    "    if A.shape[0] != q.shape[0]:\n",
    "        raise ValueError(\"Input vector q must have the same size as the matrix A.\")\n",
    "    q = q / np.linalg.norm(q)\n",
    "    Q = np.array([q])\n",
    "    r = A @ q\n",
    "    alpha = []\n",
    "    beta = []\n",
    "    alpha.append(q @ r)\n",
    "    r = r - alpha[0] * q\n",
    "    beta.append(np.linalg.norm(r))\n",
    "    count = 0\n",
    "    for j in range(1, m):\n",
    "        q = r / beta[j - 1]\n",
    "        for q_basis in Q[:-1]:\n",
    "            if np.abs(q @ q_basis) > toll:\n",
    "                for q_bbasis in Q[:-1]:\n",
    "                    q = q - (q @ q_bbasis) * q_bbasis\n",
    "                    count += 1\n",
    "                break\n",
    "        q = q / np.linalg.norm(q)\n",
    "        Q = np.vstack((Q, q))\n",
    "        r = A @ q - beta[j - 1] * Q[j - 1]\n",
    "        alpha.append(q @ r)\n",
    "        r = r - alpha[j] * q\n",
    "        beta.append(np.linalg.norm(r))\n",
    "\n",
    "        if np.abs(beta[j]) < 1e-15:\n",
    "            return Q, alpha, beta[:-1]\n",
    "\n",
    "\n",
    "    return Q, alpha, beta[:-1]\n",
    "\n",
    "\n",
    "#@jit(parallel=True)  \n",
    "def Lanczos_PRO(A, q,  m=None, toll=np.sqrt(np.finfo(float).eps)):\n",
    "    \"\"\"\n",
    "    Lanczos algorithm for symmetric matrices\n",
    "    :param A: symmetric matrix square matrix of size n\n",
    "    :param q: initial vector\n",
    "    :param m: number of eigenvalues to compute. m<=n\n",
    "    :param toll: tolerance for the computation\n",
    "\n",
    "    :return: Q, alpha, beta\n",
    "    Q: orthogonal matrix of size n x m\n",
    "    alpha: vector of size m. Diagonal of the tridiagonal matrix\n",
    "    beta: vector of size m-1. Upper diagonal of the tridiagonal matrix\n",
    "    \"\"\"\n",
    "    if m==None:\n",
    "        m=A.shape[0]\n",
    "        \n",
    "    q=q/np.linalg.norm(q)\n",
    "    #Q=np.array([q])\n",
    "    Q = np.zeros((m, A.shape[0]))\n",
    "    Q[0] = q\n",
    "    r=A@q\n",
    "    alpha=[]\n",
    "    beta=[]\n",
    "    alpha.append(q@r)\n",
    "    r=r-alpha[0]*q\n",
    "    beta.append(np.linalg.norm(r))\n",
    "\n",
    "    for j in range(1, m):\n",
    "        q=r/beta[j-1]\n",
    "        if np.any(np.abs(q@Q[:j-1].T)>toll):\n",
    "            for q_bbasis in Q[:j-1]:\n",
    "                q = q - (q @ q_bbasis) * q_bbasis\n",
    "            # for i in prange(j-1):\n",
    "            #     q = q - (q @ Q[i]) * Q[i]\n",
    "\n",
    "        q=q/np.linalg.norm(q)\n",
    "        Q[j]=q\n",
    "        r=A@q-beta[j-1]*Q[j-1]\n",
    "        alpha.append(q@r)\n",
    "        r=r-alpha[j]*q\n",
    "        beta.append(np.linalg.norm(r))\n",
    "\n",
    "        if np.abs(beta[j])<1e-15:\n",
    "            \n",
    "            return Q, alpha, beta[:-1]\n",
    "    return Q, alpha, beta[:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 4.87741 s\n",
      "File: /tmp/ipykernel_27411/3254536551.py\n",
      "Function: Lanczos_PRO_original at line 6\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     6                                           def Lanczos_PRO_original(A, q, m=None, toll=np.sqrt(np.finfo(float).eps)):\n",
      "     7                                               \"\"\"\n",
      "     8                                               Perform the Lanczos algorithm for symmetric matrices.\n",
      "     9                                               This function computes an orthogonal matrix Q and tridiagonal matrix T such that A ≈ Q * T * Q.T,\n",
      "    10                                               where A is a symmetric matrix. The algorithm is useful for finding a few eigenvalues and eigenvectors\n",
      "    11                                               of large symmetric matrices.\n",
      "    12                                               Args:\n",
      "    13                                                   A (np.ndarray): A symmetric square matrix of size n x n.\n",
      "    14                                                   q (np.ndarray): Initial vector of size n.\n",
      "    15                                                   m (int, optional): Number of eigenvalues to compute. Must be less than or equal to n.\n",
      "    16                                                                      If None, defaults to the size of A.\n",
      "    17                                           \n",
      "    18                                           \n",
      "    19                                                   tuple: A tuple (Q, alpha, beta) where:\n",
      "    20                                           \n",
      "    21                                           \n",
      "    22                                                       - Q (np.ndarray): Orthogonal matrix of size n x m.\n",
      "    23                                           \n",
      "    24                                           \n",
      "    25                                                       - alpha (np.ndarray): Vector of size m containing the diagonal elements of the tridiagonal matrix.\n",
      "    26                                           \n",
      "    27                                           \n",
      "    28                                                       - beta (np.ndarray): Vector of size m-1 containing the off-diagonal elements of the tridiagonal matrix.\n",
      "    29                                               Raises:\n",
      "    30                                                   ValueError: If the input matrix A is not square or if m is greater than the size of A.\n",
      "    31                                               \"\"\"\n",
      "    32         1       3344.0   3344.0      0.0      if m == None:\n",
      "    33         1       5570.0   5570.0      0.0          m = A.shape[0]\n",
      "    34                                           \n",
      "    35         1       2013.0   2013.0      0.0      if A.shape[0] != A.shape[1]:\n",
      "    36                                                   raise ValueError(\"Input matrix A must be square.\")\n",
      "    37                                           \n",
      "    38         1       1181.0   1181.0      0.0      if A.shape[0] != q.shape[0]:\n",
      "    39                                                   raise ValueError(\"Input vector q must have the same size as the matrix A.\")\n",
      "    40         1     252496.0 252496.0      0.0      q = q / np.linalg.norm(q)\n",
      "    41         1      16219.0  16219.0      0.0      Q = np.array([q])\n",
      "    42         1    4555088.0    5e+06      0.1      r = A @ q\n",
      "    43         1       1525.0   1525.0      0.0      alpha = []\n",
      "    44         1       1529.0   1529.0      0.0      beta = []\n",
      "    45         1      44248.0  44248.0      0.0      alpha.append(q @ r)\n",
      "    46         1      65391.0  65391.0      0.0      r = r - alpha[0] * q\n",
      "    47         1     116705.0 116705.0      0.0      beta.append(np.linalg.norm(r))\n",
      "    48         1       1019.0   1019.0      0.0      count = 0\n",
      "    49      1000     703341.0    703.3      0.0      for j in range(1, m):\n",
      "    50       999    3860539.0   3864.4      0.1          q = r / beta[j - 1]\n",
      "    51    251149  154207053.0    614.0      3.2          for q_basis in Q[:-1]:\n",
      "    52    250645 1196742890.0   4774.7     24.5              if np.abs(q @ q_basis) > toll:\n",
      "    53    248846  153823281.0    618.1      3.2                  for q_bbasis in Q[:-1]:\n",
      "    54    248351 1825378704.0   7350.0     37.4                      q = q - (q @ q_bbasis) * q_bbasis\n",
      "    55    248351   94255319.0    379.5      1.9                      count += 1\n",
      "    56       495     301139.0    608.4      0.0                  break\n",
      "    57       999   23841027.0  23864.9      0.5          q = q / np.linalg.norm(q)\n",
      "    58       999  612975994.0 613589.6     12.6          Q = np.vstack((Q, q))\n",
      "    59       999  770312978.0 771084.1     15.8          r = A @ q - beta[j - 1] * Q[j - 1]\n",
      "    60       999    4579629.0   4584.2      0.1          alpha.append(q @ r)\n",
      "    61       999    5749615.0   5755.4      0.1          r = r - alpha[j] * q\n",
      "    62       999   22063984.0  22086.1      0.5          beta.append(np.linalg.norm(r))\n",
      "    63                                           \n",
      "    64       999    3536158.0   3539.7      0.1          if np.abs(beta[j]) < 1e-15:\n",
      "    65                                                       return Q, alpha, beta[:-1]\n",
      "    66                                           \n",
      "    67                                           \n",
      "    68         1      11086.0  11086.0      0.0      return Q, alpha, beta[:-1]\n",
      "\n",
      "Total time: 3.10773 s\n",
      "File: /tmp/ipykernel_27411/3254536551.py\n",
      "Function: Lanczos_PRO at line 72\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    72                                           def Lanczos_PRO(A, q,  m=None, toll=np.sqrt(np.finfo(float).eps)):\n",
      "    73                                               \"\"\"\n",
      "    74                                               Lanczos algorithm for symmetric matrices\n",
      "    75                                               :param A: symmetric matrix square matrix of size n\n",
      "    76                                               :param q: initial vector\n",
      "    77                                               :param m: number of eigenvalues to compute. m<=n\n",
      "    78                                               :param toll: tolerance for the computation\n",
      "    79                                           \n",
      "    80                                               :return: Q, alpha, beta\n",
      "    81                                               Q: orthogonal matrix of size n x m\n",
      "    82                                               alpha: vector of size m. Diagonal of the tridiagonal matrix\n",
      "    83                                               beta: vector of size m-1. Upper diagonal of the tridiagonal matrix\n",
      "    84                                               \"\"\"\n",
      "    85         1       1314.0   1314.0      0.0      if m==None:\n",
      "    86         1       2373.0   2373.0      0.0          m=A.shape[0]\n",
      "    87                                                   \n",
      "    88         1      53985.0  53985.0      0.0      q=q/np.linalg.norm(q)\n",
      "    89                                               #Q=np.array([q])\n",
      "    90         1      41402.0  41402.0      0.0      Q = np.zeros((m, A.shape[0]))\n",
      "    91         1       7970.0   7970.0      0.0      Q[0] = q\n",
      "    92         1     142288.0 142288.0      0.0      r=A@q\n",
      "    93         1        837.0    837.0      0.0      alpha=[]\n",
      "    94         1        592.0    592.0      0.0      beta=[]\n",
      "    95         1       9391.0   9391.0      0.0      alpha.append(q@r)\n",
      "    96         1      13301.0  13301.0      0.0      r=r-alpha[0]*q\n",
      "    97         1      30100.0  30100.0      0.0      beta.append(np.linalg.norm(r))\n",
      "    98                                           \n",
      "    99      1000     615059.0    615.1      0.0      for j in range(1, m):\n",
      "   100       999    3812643.0   3816.5      0.1          q=r/beta[j-1]\n",
      "   101       999  368233241.0 368601.8     11.8          if np.any(np.abs(q@Q[:j-1].T)>toll):\n",
      "   102    248846  161616867.0    649.5      5.2              for q_bbasis in Q[:j-1]:\n",
      "   103    248351 1819551379.0   7326.5     58.5                  q = q - (q @ q_bbasis) * q_bbasis\n",
      "   104                                                       # for i in prange(j-1):\n",
      "   105                                                       #     q = q - (q @ Q[i]) * Q[i]\n",
      "   106                                           \n",
      "   107       999   30050968.0  30081.0      1.0          q=q/np.linalg.norm(q)\n",
      "   108       999   11529028.0  11540.6      0.4          Q[j]=q\n",
      "   109       999  678708711.0 679388.1     21.8          r=A@q-beta[j-1]*Q[j-1]\n",
      "   110       999    4199526.0   4203.7      0.1          alpha.append(q@r)\n",
      "   111       999    5341672.0   5347.0      0.2          r=r-alpha[j]*q\n",
      "   112       999   20055502.0  20075.6      0.6          beta.append(np.linalg.norm(r))\n",
      "   113                                           \n",
      "   114       999    3699773.0   3703.5      0.1          if np.abs(beta[j])<1e-15:\n",
      "   115                                                       \n",
      "   116                                                       return Q, alpha, beta[:-1]\n",
      "   117         1      11841.0  11841.0      0.0      return Q, alpha, beta[:-1]\n",
      "\n",
      "Optimized function time: 3.33388352394104\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "size = 1000\n",
    "A = np.random.rand(size, size)\n",
    "A = (A + A.T) / 2\n",
    "A=np.array(A, dtype=float)\n",
    "q = np.random.rand(size)\n",
    "lp = LineProfiler()\n",
    "lp.add_function(Lanczos_PRO_original)\n",
    "result = lp.run('Lanczos_PRO_original(A, q)')\n",
    "#lp.print_stats()\n",
    "#Q, alpha, beta = Lanczos_PRO(A, q)\n",
    "\n",
    "\n",
    "\n",
    "t_s=time()\n",
    "lp.add_function(Lanczos_PRO)\n",
    "result = lp.run('Lanczos_PRO(A, q)')\n",
    "lp.print_stats()\n",
    "\n",
    "t_e=time()\n",
    "print(f\"Optimized function time: {t_e-t_s}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the line profiler we can see that the most expensive operation is associated with reorthogonalization. To improve this a slight modified version was implemented. Also the np.vstack operation was quite costly, so it was replaced with a simple assignment. This little adjustment allowed to almost halve the cost of the Lanczos Algorithm. In the final version the decorator jit, from numba packeage was additionally used. The only portion of code that could be paralleliza using prange is the for associated with reorthogonalization, but this slows down the performance.\n",
    "\n",
    "### QR algorithm\n",
    "\n",
    "The QR algorithm, computed with the Given rotation is difficult to be parallelized. By exploiting the tridiagonal shape fo the matrix, it can be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m lp_QR \u001b[38;5;241m=\u001b[39m LineProfiler()\n\u001b[1;32m     86\u001b[0m lp_QR\u001b[38;5;241m.\u001b[39madd_function(QR_method)\n\u001b[0;32m---> 87\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlp_QR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQR_method(T)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m lp_QR\u001b[38;5;241m.\u001b[39madd_function(QR_method_optimized)\n\u001b[1;32m     91\u001b[0m result \u001b[38;5;241m=\u001b[39m lp_QR\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQR_method_optimized(T)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/line_profiler/line_profiler.py:178\u001b[0m, in \u001b[0;36mLineProfiler.run\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[1;32m    177\u001b[0m main_dict \u001b[38;5;241m=\u001b[39m __main__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/line_profiler/line_profiler.py:185\u001b[0m, in \u001b[0;36mLineProfiler.runctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_by_count()\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_by_count()\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mQR_method\u001b[0;34m(A_copy, tol, max_iter)\u001b[0m\n\u001b[1;32m     26\u001b[0m     R\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39meye(A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     27\u001b[0m     R[i: i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m, i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([[Matrix_trigonometry[i, \u001b[38;5;241m0\u001b[39m], Matrix_trigonometry[i, \u001b[38;5;241m1\u001b[39m]], [\u001b[38;5;241m-\u001b[39mMatrix_trigonometry[i, \u001b[38;5;241m1\u001b[39m], Matrix_trigonometry[i, \u001b[38;5;241m0\u001b[39m]]])\n\u001b[0;32m---> 28\u001b[0m     Q \u001b[38;5;241m=\u001b[39m Q\u001b[38;5;129m@R\u001b[39m\n\u001b[1;32m     29\u001b[0m A\u001b[38;5;241m=\u001b[39mA\u001b[38;5;129m@Q\u001b[39m\n\u001b[1;32m     30\u001b[0m A \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m@\u001b[39m Q  \u001b[38;5;66;03m# Update A\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def QR_method(A_copy, tol=1e-10, max_iter=100):\n",
    "    A = A_copy.copy()\n",
    "    iter = 0\n",
    "    Q = np.eye(A.shape[0])\n",
    "    \n",
    "    # Correctly preallocate as a 2D array (n-1, 2)\n",
    "    Matrix_trigonometry = np.zeros((A.shape[0] - 1, 2))\n",
    "\n",
    "    while np.linalg.norm(np.diag(A, -1), np.inf) > tol and iter < max_iter:\n",
    "        # Compute Givens rotation\n",
    "        for i in range(A.shape[0] - 1):\n",
    "            c = A[i, i] / np.sqrt(A[i, i] ** 2 + A[i + 1, i] ** 2)\n",
    "            s = -A[i + 1, i] / np.sqrt(A[i, i] ** 2 + A[i + 1, i] ** 2)\n",
    "            Matrix_trigonometry[i, :] = [c, s]  \n",
    "            R=np.eye(A.shape[0])\n",
    "            # Apply the Givens rotation to A (modify in place)\n",
    "            R[i:i+2, i:i+2] = np.array([[c, -s], [s, c]])\n",
    "            A= R @ A\n",
    "            A[i+1, i] = 0 \n",
    "\n",
    "\n",
    "        Q=np.eye(A.shape[0])\n",
    "        i=0\n",
    "        Q[0:2, 0:2]=np.array([[Matrix_trigonometry[i, 0], Matrix_trigonometry[i, 1]], [-Matrix_trigonometry[i, 1], Matrix_trigonometry[i, 0]]])\n",
    "        for i in range(1, A.shape[0]-1):\n",
    "            R=np.eye(A.shape[0])\n",
    "            R[i: i+2, i:i+2]=np.array([[Matrix_trigonometry[i, 0], Matrix_trigonometry[i, 1]], [-Matrix_trigonometry[i, 1], Matrix_trigonometry[i, 0]]])\n",
    "            Q = Q@R\n",
    "        A=A@Q\n",
    "        A = A @ Q  # Update A\n",
    "        iter += 1\n",
    "\n",
    "    if iter == max_iter:\n",
    "        print(\"QR method did not converge\")\n",
    "\n",
    "    return np.diag(A), Q\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def QR_method_optimized(A_copy, tol=1e-10, max_iter=100):\n",
    "    A = A_copy.copy()\n",
    "    iter = 0\n",
    "    Q = np.eye(A.shape[0])\n",
    "    \n",
    "    # Correctly preallocate as a 2D array (n-1, 2)\n",
    "    Matrix_trigonometry = np.zeros((A.shape[0] - 1, 2))\n",
    "    d=np.zeros(A.shape[0])\n",
    "    #while np.linalg.norm((np.diag(A, -1)), np.inf) > tol and iter < max_iter:\n",
    "    while np.linalg.norm((np.diag(A, 0)-d)/np.diag(A, 0), np.inf) > tol and iter < max_iter:\n",
    "        # Compute Givens rotation\n",
    "        d=np.diag(A, 0)\n",
    "        for i in range(A.shape[0] - 1):\n",
    "            c = A[i, i] / np.sqrt(A[i, i] ** 2 + A[i + 1, i] ** 2)\n",
    "            s = -A[i + 1, i] / np.sqrt(A[i, i] ** 2 + A[i + 1, i] ** 2)\n",
    "            Matrix_trigonometry[i, :] = [c, s]  \n",
    "\n",
    "            # Apply the Givens rotation to A (modify in place)\n",
    "            R = np.array([[c, -s], [s, c]])\n",
    "            A[i:i+2, i:] = R @ A[i:i+2, i:]\n",
    "            A[i+1, i] = 0 \n",
    "\n",
    "        # Construct full Q matrix from stored Givens rotations\n",
    "        Q = np.eye(A.shape[0])\n",
    "        for i in range(A.shape[0] - 1):\n",
    "            R=np.array([[Matrix_trigonometry[i, 0], Matrix_trigonometry[i, 1]], [-Matrix_trigonometry[i, 1], Matrix_trigonometry[i, 0]]])\n",
    "            Q[:, i:i+2] = Q[:, i:i+2]@R\n",
    "        A = A @ Q  # Update A\n",
    "        iter += 1\n",
    "\n",
    "    return np.diag(A), Q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "size = 300\n",
    "A = np.random.rand(size, size)\n",
    "A = (A + A.T) / 2\n",
    "x0 = np.random.rand(size)\n",
    "\n",
    "q, alpha, beta = Lanczos_PRO(A, x0, size)\n",
    "\n",
    "T=np.diag(alpha)+np.diag(beta, k=1)+np.diag(beta, k=-1)\n",
    "QR_method_optimized(T)\n",
    "lp_QR = LineProfiler()\n",
    "lp_QR.add_function(QR_method)\n",
    "result = lp_QR.run('QR_method(T)')\n",
    "\n",
    "\n",
    "lp_QR.add_function(QR_method_optimized)\n",
    "result = lp_QR.run('QR_method_optimized(T)')\n",
    "lp_QR.print_stats()\n",
    "# t_s=time()\n",
    "# result= QR_method_optimized(T)\n",
    "# t_e=time()\n",
    "# print(f\"Optimized function time: {t_e-t_s}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first simple optimization concern the memory. The Rotation matrix at each iteration is completly defined by the value of the sine and cosine (s, c) of the rotation angle, which can be assembled in a $2 \\times 2 $ matrix, and the position of this block in the $n \\times n $ rotation matrix $G(i, \\theta_i)$ matrix, with $i=0, 1, 2, ..., n-2$. Therefore rather than storing $n-1$ $n \\times n$ rotation matrix, it is possible store all the inforamtion they carry out in a $(n-1)\\times 2$ matrix in which the $i$-th row has the value of sine and cosine associated with the matrix $G(i, \\theta_i)$.\n",
    "\n",
    "Profiling the QR method shows as the most expensive operatation are the matrix matrix multiplication, which adds up to the 92% of the function total run. Knowing the structure of the matrix $G(i, \\theta_i)$ allow to reduce the size of the matrix multiplication (see lines 53 and 60). A final 98% speed up of the code was achieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8.5068e+01\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "size = 5000\n",
    "A = np.random.rand(size, size)\n",
    "A = (A + A.T) / 2\n",
    "x0 = np.random.rand(size)\n",
    "q, alpha, beta = Lanczos_PRO(A, x0, size)\n",
    "\n",
    "t_s=time()\n",
    "np.linalg.eig(A)\n",
    "t_e=time()\n",
    "\n",
    "print(f\"{t_e-t_s: .4e}\")\n",
    "\n",
    "# T=np.diag(alpha)+np.diag(beta, k=1)+np.diag(beta, k=-1)\n",
    "# t_s=time()\n",
    "# result= QR_method_optimized(T, max_iter=5000, tol=1e-6)\n",
    "# t_e=time()\n",
    "# print(f\"Optimized function time: {t_e-t_s}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
